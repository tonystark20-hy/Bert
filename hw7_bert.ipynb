{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"hw7_bert","provenance":[{"file_id":"https://github.com/ga642381/ML2021-Spring/blob/main/HW07/HW07.ipynb","timestamp":1624346301710}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f7d0df1738234ae8b46ac467c9198a94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a8b774e0645479d943599ea1f9fbccd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f8f61ab1e4e4a1fa7470753647d2e49","IPY_MODEL_4abf5291edbf483fb12e0f3b23a34d79"]}},"1a8b774e0645479d943599ea1f9fbccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f8f61ab1e4e4a1fa7470753647d2e49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bd7270f243944227bb9e7d9b4a183b45","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fad53481e12d468caebe3f0d6706bcc4"}},"4abf5291edbf483fb12e0f3b23a34d79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e4f43c39639c40d1a4ab2ff5910db435","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1684/1684 [07:03&lt;00:00,  3.97it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f2b49a670b84c85a3055a86bcfc01de"}},"bd7270f243944227bb9e7d9b4a183b45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fad53481e12d468caebe3f0d6706bcc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4f43c39639c40d1a4ab2ff5910db435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9f2b49a670b84c85a3055a86bcfc01de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c8a5cb3045548ab9bce3c6101ce8452":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fbe88b9a9ad24acaa6c01012c703748a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7839482c5ef848d8b2fefafe65c83b29","IPY_MODEL_ee923f570b5243ddb72afab39e0b736b"]}},"fbe88b9a9ad24acaa6c01012c703748a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7839482c5ef848d8b2fefafe65c83b29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cbef0d26fd5742e694f05ed672f0678c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3524,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3524,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8dc0d06184d4ce59955f8afbd0284ef"}},"ee923f570b5243ddb72afab39e0b736b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f920a4c55a7b43248226d13bf3d0f785","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3524/3524 [02:24&lt;00:00, 24.46it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dea1650bf6104698960668895f367664"}},"cbef0d26fd5742e694f05ed672f0678c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f8dc0d06184d4ce59955f8afbd0284ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f920a4c55a7b43248226d13bf3d0f785":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dea1650bf6104698960668895f367664":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a08110e1deba4ac49b7fef7f50051c9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d28469937cf43dbac7893dd64dd667b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a51881c51f04473fb6d6ceb2a3a434e9","IPY_MODEL_90fdf715e31a46bd94dbf3922a261afc"]}},"7d28469937cf43dbac7893dd64dd667b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a51881c51f04473fb6d6ceb2a3a434e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1d1a8a7518cb44999e0a5a49145c33b3","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98b33d9dd2374b29a299044b57f47f74"}},"90fdf715e31a46bd94dbf3922a261afc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_435cf3785db8491cad659ee656d6c46b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1684/1684 [06:59&lt;00:00,  4.02it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2a0f7d59342481395ece924dfe9aa90"}},"1d1a8a7518cb44999e0a5a49145c33b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"98b33d9dd2374b29a299044b57f47f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"435cf3785db8491cad659ee656d6c46b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2a0f7d59342481395ece924dfe9aa90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01cc62fd4eb2457389e5d1e565b450ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1534d314d7d40da9920e91023d1eeb3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0ed112d4ccee4a19bf08209bce6c15b7","IPY_MODEL_127270bec4c340cd9414270398947878"]}},"e1534d314d7d40da9920e91023d1eeb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ed112d4ccee4a19bf08209bce6c15b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d6a0bf3aaff45b99a246a55575e372c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3524,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3524,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25c4310bfe3b4af2ad9b78b5573385e4"}},"127270bec4c340cd9414270398947878":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8160a98a24b64e7a95e77afa7de60065","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3524/3524 [03:32&lt;00:00, 16.57it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_478660fbd14d4548bcdcca810e88dd94"}},"8d6a0bf3aaff45b99a246a55575e372c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"25c4310bfe3b4af2ad9b78b5573385e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8160a98a24b64e7a95e77afa7de60065":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"478660fbd14d4548bcdcca810e88dd94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a0e6551fc3b4f3c84ba6a1c9423ceeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4148c6e3b5744612be122507b9c418fd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_10e34d88289a490584167c46b4bb3dfa","IPY_MODEL_4fc4c1a3ace141198c917efc0dab06f8"]}},"4148c6e3b5744612be122507b9c418fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10e34d88289a490584167c46b4bb3dfa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8fa1b3058386474098367c68506e1700","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1684,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1684,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_adac704f7a774b059397264564079de4"}},"4fc4c1a3ace141198c917efc0dab06f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_225fbd9bc66b49aaaf7274c72f87cc64","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1684/1684 [06:57&lt;00:00,  4.03it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac80af9ab3b14e8a8d1bc975cdb1844d"}},"8fa1b3058386474098367c68506e1700":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"adac704f7a774b059397264564079de4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"225fbd9bc66b49aaaf7274c72f87cc64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ac80af9ab3b14e8a8d1bc975cdb1844d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfa70781babb4b74b31a0160390a28d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9f186e0653d747f28e6b9c089a002b3f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b286120063944d8389ec0ddaa49afadf","IPY_MODEL_d57586896921497e83ee831f92008a14"]}},"9f186e0653d747f28e6b9c089a002b3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b286120063944d8389ec0ddaa49afadf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aa0d0643d3614bc3a0b1536ab32efc7f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3524,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3524,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da224a8368ca4c24972b65b87f0ba597"}},"d57586896921497e83ee831f92008a14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_906a7d7e185449e7928facdc73279146","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3524/3524 [02:10&lt;00:00, 27.08it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63ac3625a9f94485b2e1929b44b1259b"}},"aa0d0643d3614bc3a0b1536ab32efc7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da224a8368ca4c24972b65b87f0ba597":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"906a7d7e185449e7928facdc73279146":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63ac3625a9f94485b2e1929b44b1259b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14306b8a3fab4e2bbfa73b0a4d513a3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8baaa920770f45edbaa75617586d21ca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_89a99d3d26a14402ace004b98695d480","IPY_MODEL_08fc2ad196f845c5bc275aca2265ec84"]}},"8baaa920770f45edbaa75617586d21ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89a99d3d26a14402ace004b98695d480":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec35dd5dde0c496db7e8f62816d2d143","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3493,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3493,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_078f6e9d2e0949599be4971da928a7f3"}},"08fc2ad196f845c5bc275aca2265ec84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d5919a9f9974cff9916e1bd4a7f7efb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3493/3493 [02:04&lt;00:00, 27.95it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_edc87f34a76a4fe19623cba8c5d4c3b4"}},"ec35dd5dde0c496db7e8f62816d2d143":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"078f6e9d2e0949599be4971da928a7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d5919a9f9974cff9916e1bd4a7f7efb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"edc87f34a76a4fe19623cba8c5d4c3b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"xvSGDbExff_I"},"source":["# **Homework 7 - Bert (Question Answering)**\n","\n","If you have any questions, feel free to email us at ntu-ml-2021spring-ta@googlegroups.com\n","\n","\n","\n","Slide:    [Link](https://docs.google.com/presentation/d/1aQoWogAQo_xVJvMQMrGaYiWzuyfO0QyLLAhiMwFyS2w)　Kaggle: [Link](https://www.kaggle.com/c/ml2021-spring-hw7)　Data: [Link](https://drive.google.com/uc?id=1znKmX08v9Fygp-dgwo7BKiLIf2qL1FH1)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WGOr_eS3wJJf"},"source":["## Task description\n","- Chinese Extractive Question Answering\n","  - Input: Paragraph + Question\n","  - Output: Answer\n","\n","- Objective: Learn how to fine tune a pretrained model on downstream task using transformers\n","\n","- Todo\n","    - Fine tune a pretrained chinese BERT model\n","    - Change hyperparameters (e.g. doc_stride)\n","    - Apply linear learning rate decay\n","    - Try other pretrained models\n","    - Improve preprocessing\n","    - Improve postprocessing\n","- Training tips\n","    - Automatic mixed precision\n","    - Gradient accumulation\n","    - Ensemble\n","\n","- Estimated training time (tesla t4 with automatic mixed precision enabled)\n","    - Simple: 8mins\n","    - Medium: 8mins\n","    - Strong: 25mins\n","    - Boss: 2hrs\n","  "]},{"cell_type":"markdown","metadata":{"id":"TJ1fSAJE2oaC"},"source":["## Download Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vF6Mdzh4gAA","executionInfo":{"status":"ok","timestamp":1624868792627,"user_tz":-480,"elapsed":1067,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"b9c1c091-918e-430a-aa6e-98176d58a759"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/BERT/\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPrc4Eie9Yo5","executionInfo":{"status":"ok","timestamp":1624868794948,"user_tz":-480,"elapsed":1286,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"60debcd2-5b8e-4f9c-a528-15154f3a78b2"},"source":["# Download link 1\n","!gdown --id '1znKmX08v9Fygp-dgwo7BKiLIf2qL1FH1' --output hw7_data.zip\n","\n","# Download Link 2 (if the above link fails) \n","# !gdown --id '1pOu3FdPdvzielUZyggeD7KDnVy9iW1uC' --output hw7_data.zip\n","\n","!unzip -o hw7_data.zip\n","\n","# For this HW, K80 < P4 < T4 < P100 <= T4(fp16) < V100\n","!nvidia-smi"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1znKmX08v9Fygp-dgwo7BKiLIf2qL1FH1\n","To: /content/drive/My Drive/BERT/hw7_data.zip\n","\r0.00B [00:00, ?B/s]\r6.29MB [00:00, 62.7MB/s]\r7.71MB [00:00, 67.8MB/s]\n","Archive:  hw7_data.zip\n","  inflating: hw7_dev.json            \n","  inflating: hw7_test.json           \n","  inflating: hw7_train.json          \n","Mon Jun 28 08:26:34 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   77C    P0    33W /  70W |   5460MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TevOvhC03m0h"},"source":["## Install transformers\n","\n","Documentation for the toolkit:　https://huggingface.co/transformers/"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbxWFX_jpDom","executionInfo":{"status":"ok","timestamp":1624868797979,"user_tz":-480,"elapsed":3034,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"f27755b1-7a5e-49e3-be7b-5906a84d1bfc"},"source":["# You are allowed to change version of transformers or use other toolkits\n","!pip install transformers==4.5.0"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==4.5.0 in /usr/local/lib/python3.7/dist-packages (4.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.0.45)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.5.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2021.5.30)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8dKM4yCh4LI_"},"source":["## Import Packages"]},{"cell_type":"code","metadata":{"id":"WOTHHtWJoahe","executionInfo":{"status":"ok","timestamp":1624868797979,"user_tz":-480,"elapsed":6,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}}},"source":["import json\n","import numpy as np\n","import random\n","import torch\n","from torch.utils.data import DataLoader, Dataset \n","from transformers import AdamW, BertForQuestionAnswering, BertTokenizerFast\n","\n","from tqdm.auto import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Fix random seed for reproducibility\n","def same_seeds(seed):\n","\t  torch.manual_seed(seed)\n","\t  if torch.cuda.is_available():\n","\t\t    torch.cuda.manual_seed(seed)\n","\t\t    torch.cuda.manual_seed_all(seed)\n","\t  np.random.seed(seed)\n","\t  random.seed(seed)\n","\t  torch.backends.cudnn.benchmark = False\n","\t  torch.backends.cudnn.deterministic = True\n","same_seeds(0)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pBtSZP1SKQO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624868800133,"user_tz":-480,"elapsed":2158,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"4df2af67-3fd7-4db7-e348-2786b4951c84"},"source":["# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\t\n","fp16_training = True\n","\n","if fp16_training:\n","    !pip install accelerate==0.2.0\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device\n","\n","# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: accelerate==0.2.0 in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.2.0) (1.9.0+cu102)\n","Requirement already satisfied: pyaml>=20.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.2.0) (20.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate==0.2.0) (3.7.4.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=20.4.0->accelerate==0.2.0) (3.13)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2YgXHuVLp_6j"},"source":["## Load Model and Tokenizer\n","\n","\n","\n","\n"," "]},{"cell_type":"code","metadata":{"id":"xyBCYGjAp3ym","executionInfo":{"status":"ok","timestamp":1624868802954,"user_tz":-480,"elapsed":2825,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}}},"source":["# model = BertForQuestionAnswering.from_pretrained(\"bert-base-chinese\").to(device)\n","# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-chinese\")\n","model = BertForQuestionAnswering.from_pretrained(\"uer/roberta-base-chinese-extractive-qa\").to(device)\n","tokenizer = BertTokenizerFast.from_pretrained(\"uer/roberta-base-chinese-extractive-qa\")\n","\n","# You can safely ignore the warning message (it pops up because new prediction heads for QA are initialized randomly)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Td-GTmk5OW4"},"source":["## Read Data\n","\n","- Training set: 26935 QA pairs\n","- Dev set: 3523  QA pairs\n","- Test set: 3492  QA pairs\n","\n","- {train/dev/test}_questions:\t\n","  - List of dicts with the following keys:\n","   - id (int)\n","   - paragraph_id (int)\n","   - question_text (string)\n","   - answer_text (string)\n","   - answer_start (int)\n","   - answer_end (int)\n","- {train/dev/test}_paragraphs: \n","  - List of strings\n","  - paragraph_ids in questions correspond to indexs in paragraphs\n","  - A paragraph may be used by several questions "]},{"cell_type":"code","metadata":{"id":"NvX7hlepogvu","executionInfo":{"status":"ok","timestamp":1624868802956,"user_tz":-480,"elapsed":6,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}}},"source":["def read_data(file):\n","    with open(file, 'r', encoding=\"utf-8\") as reader:\n","        data = json.load(reader)\n","    return data[\"questions\"], data[\"paragraphs\"]\n","\n","train_questions, train_paragraphs = read_data(\"hw7_train.json\")\n","dev_questions, dev_paragraphs = read_data(\"hw7_dev.json\")\n","test_questions, test_paragraphs = read_data(\"hw7_test.json\")"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fm0rpTHq0e4N"},"source":["## Tokenize Data"]},{"cell_type":"code","metadata":{"id":"rTZ6B70Hoxie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624868809819,"user_tz":-480,"elapsed":6867,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"5f5fe589-a7fd-4501-c3ed-8e4cd24c25b4"},"source":["# Tokenize questions and paragraphs separately\n","# 「add_special_tokens」 is set to False since special tokens will be added when tokenized questions and paragraphs are combined in datset __getitem__ \n","\n","train_questions_tokenized = tokenizer([train_question[\"question_text\"] for train_question in train_questions], add_special_tokens=False)\n","dev_questions_tokenized = tokenizer([dev_question[\"question_text\"] for dev_question in dev_questions], add_special_tokens=False)\n","test_questions_tokenized = tokenizer([test_question[\"question_text\"] for test_question in test_questions], add_special_tokens=False) \n","\n","train_paragraphs_tokenized = tokenizer(train_paragraphs, add_special_tokens=False)\n","dev_paragraphs_tokenized = tokenizer(dev_paragraphs, add_special_tokens=False)\n","test_paragraphs_tokenized = tokenizer(test_paragraphs, add_special_tokens=False)\n","\n","# You can safely ignore the warning message as tokenized sequences will be futher processed in datset __getitem__ before passing to model"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Ws8c8_4d5UCI"},"source":["## Dataset and Dataloader"]},{"cell_type":"code","metadata":{"id":"Xjooag-Swnuh","executionInfo":{"status":"ok","timestamp":1624868810358,"user_tz":-480,"elapsed":550,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}}},"source":["class QA_Dataset(Dataset):\n","    def __init__(self, split, questions, tokenized_questions, tokenized_paragraphs):\n","        self.split = split\n","        self.questions = questions\n","        self.tokenized_questions = tokenized_questions\n","        self.tokenized_paragraphs = tokenized_paragraphs\n","        self.max_question_len = 40\n","        self.max_paragraph_len = 150\n","        \n","        ##### TODO: Change value of doc_stride #####\n","        self.doc_stride = 75 #150\n","\n","        # Input sequence length = [CLS] + question + [SEP] + paragraph + [SEP]\n","        self.max_seq_len = 1 + self.max_question_len + 1 + self.max_paragraph_len + 1\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question = self.questions[idx]\n","        tokenized_question = self.tokenized_questions[idx]\n","        tokenized_paragraph = self.tokenized_paragraphs[question[\"paragraph_id\"]]\n","\n","        ##### TODO: Preprocessing #####\n","        # Hint: How to prevent model from learning something it should not learn\n","\n","        if self.split == \"train\":\n","            # Convert answer's start/end positions in paragraph_text to start/end positions in tokenized_paragraph  \n","            answer_start_token = tokenized_paragraph.char_to_token(question[\"answer_start\"])\n","            answer_end_token = tokenized_paragraph.char_to_token(question[\"answer_end\"])\n","\n","            # A single window is obtained by slicing the portion of paragraph containing the answer\n","            # mid = (answer_start_token + answer_end_token) // 2\n","            # paragraph_start = max(0, min(mid - self.max_paragraph_len // 2, len(tokenized_paragraph) - self.max_paragraph_len))\n","            random_start = random.randrange(answer_end_token - self.max_paragraph_len + 1, answer_start_token + 1)\n","            paragraph_start = max(0, min(random_start, len(tokenized_paragraph) - self.max_paragraph_len))\n","            paragraph_end = paragraph_start + self.max_paragraph_len\n","            \n","            # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n","            input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102] \n","            input_ids_paragraph = tokenized_paragraph.ids[paragraph_start : paragraph_end] + [102]\t\t\n","            \n","            # Convert answer's start/end positions in tokenized_paragraph to start/end positions in the window  \n","            answer_start_token += len(input_ids_question) - paragraph_start\n","            answer_end_token += len(input_ids_question) - paragraph_start\n","            \n","            # Pad sequence and obtain inputs to model \n","            input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n","            return torch.tensor(input_ids), torch.tensor(token_type_ids), torch.tensor(attention_mask), answer_start_token, answer_end_token\n","\n","        # Validation/Testing\n","        else:\n","            input_ids_list, token_type_ids_list, attention_mask_list = [], [], []\n","            \n","            # Paragraph is split into several windows, each with start positions separated by step \"doc_stride\"\n","            for i in range(0, len(tokenized_paragraph), self.doc_stride):\n","                \n","                # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n","                input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n","                input_ids_paragraph = tokenized_paragraph.ids[i : i + self.max_paragraph_len] + [102]\n","                \n","                # Pad sequence and obtain inputs to model\n","                input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n","                \n","                input_ids_list.append(input_ids)\n","                token_type_ids_list.append(token_type_ids)\n","                attention_mask_list.append(attention_mask)\n","            \n","            return torch.tensor(input_ids_list), torch.tensor(token_type_ids_list), torch.tensor(attention_mask_list)\n","\n","    def padding(self, input_ids_question, input_ids_paragraph):\n","        # Pad zeros if sequence length is shorter than max_seq_len\n","        padding_len = self.max_seq_len - len(input_ids_question) - len(input_ids_paragraph)\n","        # Indices of input sequence tokens in the vocabulary\n","        input_ids = input_ids_question + input_ids_paragraph + [0] * padding_len\n","        # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\n","        token_type_ids = [0] * len(input_ids_question) + [1] * len(input_ids_paragraph) + [0] * padding_len\n","        # Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n","        attention_mask = [1] * (len(input_ids_question) + len(input_ids_paragraph)) + [0] * padding_len\n","        \n","        return input_ids, token_type_ids, attention_mask\n","\n","train_set = QA_Dataset(\"train\", train_questions, train_questions_tokenized, train_paragraphs_tokenized)\n","dev_set = QA_Dataset(\"dev\", dev_questions, dev_questions_tokenized, dev_paragraphs_tokenized)\n","test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_paragraphs_tokenized)\n","\n","train_batch_size = 16\n","\n","# Note: Do NOT change batch size of dev_loader / test_loader !\n","# Although batch size=1, it is actually a batch consisting of several windows from the same QA pair\n","train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n","dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False, pin_memory=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_H1kqhR8CdM"},"source":["## Function for Evaluation"]},{"cell_type":"code","metadata":{"id":"SqeA3PLPxOHu","executionInfo":{"status":"ok","timestamp":1624868810361,"user_tz":-480,"elapsed":15,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}}},"source":["def evaluate(data, output):\n","    ##### TODO: Postprocessing #####\n","    # There is a bug and room for improvement in postprocessing \n","    # Hint: Open your prediction file to see what is wrong \n","    \n","    answer = ''\n","    max_prob = float('-inf')\n","    num_of_windows = data[0].shape[1]\n","    # print(output)\n","\n","    for k in range(num_of_windows):\n","        # Obtain answer by choosing the most probable start position / end position\n","        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n","        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n","        \n","        # Probability of answer is calculated as sum of start_prob and end_prob\n","        prob = start_prob + end_prob\n","        \n","        # Replace answer if calculated probability is larger than previous windows\n","        if prob > max_prob:\n","            max_prob = prob\n","            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n","            answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n","    \n","    # Remove spaces in answer (e.g. \"大 金\" --> \"大金\")\n","    return answer.replace(' ','')"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rzHQit6eMnKG"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f7d0df1738234ae8b46ac467c9198a94","1a8b774e0645479d943599ea1f9fbccd","9f8f61ab1e4e4a1fa7470753647d2e49","4abf5291edbf483fb12e0f3b23a34d79","bd7270f243944227bb9e7d9b4a183b45","fad53481e12d468caebe3f0d6706bcc4","e4f43c39639c40d1a4ab2ff5910db435","9f2b49a670b84c85a3055a86bcfc01de","3c8a5cb3045548ab9bce3c6101ce8452","fbe88b9a9ad24acaa6c01012c703748a","7839482c5ef848d8b2fefafe65c83b29","ee923f570b5243ddb72afab39e0b736b","cbef0d26fd5742e694f05ed672f0678c","f8dc0d06184d4ce59955f8afbd0284ef","f920a4c55a7b43248226d13bf3d0f785","dea1650bf6104698960668895f367664","a08110e1deba4ac49b7fef7f50051c9f","7d28469937cf43dbac7893dd64dd667b","a51881c51f04473fb6d6ceb2a3a434e9","90fdf715e31a46bd94dbf3922a261afc","1d1a8a7518cb44999e0a5a49145c33b3","98b33d9dd2374b29a299044b57f47f74","435cf3785db8491cad659ee656d6c46b","c2a0f7d59342481395ece924dfe9aa90","01cc62fd4eb2457389e5d1e565b450ec","e1534d314d7d40da9920e91023d1eeb3","0ed112d4ccee4a19bf08209bce6c15b7","127270bec4c340cd9414270398947878","8d6a0bf3aaff45b99a246a55575e372c","25c4310bfe3b4af2ad9b78b5573385e4","8160a98a24b64e7a95e77afa7de60065","478660fbd14d4548bcdcca810e88dd94","7a0e6551fc3b4f3c84ba6a1c9423ceeb","4148c6e3b5744612be122507b9c418fd","10e34d88289a490584167c46b4bb3dfa","4fc4c1a3ace141198c917efc0dab06f8","8fa1b3058386474098367c68506e1700","adac704f7a774b059397264564079de4","225fbd9bc66b49aaaf7274c72f87cc64","ac80af9ab3b14e8a8d1bc975cdb1844d","cfa70781babb4b74b31a0160390a28d9","9f186e0653d747f28e6b9c089a002b3f","b286120063944d8389ec0ddaa49afadf","d57586896921497e83ee831f92008a14","aa0d0643d3614bc3a0b1536ab32efc7f","da224a8368ca4c24972b65b87f0ba597","906a7d7e185449e7928facdc73279146","63ac3625a9f94485b2e1929b44b1259b"]},"id":"3Q-B6ka7xoCM","executionInfo":{"status":"ok","timestamp":1624870462696,"user_tz":-480,"elapsed":1652349,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"22d7c832-25dd-400f-acb1-ad4fcc2878fa"},"source":["num_epoch = 3\n","validation = True\n","logging_step = 100\n","learning_rate = 1e-4\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","\n","if fp16_training:\n","    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader) \n","\n","from transformers import get_scheduler\n","\n","# num_training_steps = num_epochs * len(train_dataloader)\n","num_training_steps = num_epoch * len(train_loader)\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")\n","\n","model.train()\n","\n","print(\"Start Training ...\")\n","\n","for epoch in range(num_epoch):\n","    step = 1\n","    train_loss = train_acc = 0\n","    \n","    for data in tqdm(train_loader):\t\n","        # Load all data into GPU\n","        data = [i.to(device) for i in data]\n","        \n","        # Model inputs: input_ids, token_type_ids, attention_mask, start_positions, end_positions (Note: only \"input_ids\" is mandatory)\n","        # Model outputs: start_logits, end_logits, loss (return when start_positions/end_positions are provided)  \n","        output = model(input_ids=data[0], token_type_ids=data[1], attention_mask=data[2], start_positions=data[3], end_positions=data[4])\n","\n","        # Choose the most probable start position / end position\n","        start_index = torch.argmax(output.start_logits, dim=1)\n","        end_index = torch.argmax(output.end_logits, dim=1)\n","        \n","        # Prediction is correct only if both start_index and end_index are correct\n","        train_acc += ((start_index == data[3]) & (end_index == data[4])).float().mean()\n","        train_loss += output.loss\n","        \n","        if fp16_training:\n","            accelerator.backward(output.loss)\n","        else:\n","            output.loss.backward()\n","        \n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        step += 1\n","\n","        ##### TODO: Apply linear learning rate decay #####\n","        \n","        # Print training loss and accuracy over past logging step\n","        if step % logging_step == 0:\n","            print(f\"Epoch {epoch + 1} | Step {step} | loss = {train_loss.item() / logging_step:.3f}, acc = {train_acc / logging_step:.3f}\")\n","            train_loss = train_acc = 0\n","\n","    if validation:\n","        print(\"Evaluating Dev Set ...\")\n","        model.eval()\n","        with torch.no_grad():\n","            dev_acc = 0\n","            for i, data in enumerate(tqdm(dev_loader)):\n","                output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n","                       attention_mask=data[2].squeeze(dim=0).to(device))\n","                # prediction is correct only if answer text exactly matches\n","                dev_acc += evaluate(data, output) == dev_questions[i][\"answer_text\"]\n","            print(f\"Validation | Epoch {epoch + 1} | acc = {dev_acc / len(dev_loader):.3f}\")\n","        model.train()\n","\n","# Save a model and its configuration file to the directory 「saved_model」 \n","# i.e. there are two files under the direcory 「saved_model」: 「pytorch_model.bin」 and 「config.json」\n","# Saved model can be re-loaded using 「model = BertForQuestionAnswering.from_pretrained(\"saved_model\")」\n","print(\"Saving Model ...\")\n","model_save_dir = \"saved_model\" \n","model.save_pretrained(model_save_dir)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Start Training ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7d0df1738234ae8b46ac467c9198a94","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1684.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1 | Step 100 | loss = 1.017, acc = 0.588\n","Epoch 1 | Step 200 | loss = 0.837, acc = 0.677\n","Epoch 1 | Step 300 | loss = 0.913, acc = 0.657\n","Epoch 1 | Step 400 | loss = 0.809, acc = 0.691\n","Epoch 1 | Step 500 | loss = 0.832, acc = 0.684\n","Epoch 1 | Step 600 | loss = 0.820, acc = 0.664\n","Epoch 1 | Step 700 | loss = 0.732, acc = 0.714\n","Epoch 1 | Step 800 | loss = 0.754, acc = 0.687\n","Epoch 1 | Step 900 | loss = 0.684, acc = 0.722\n","Epoch 1 | Step 1000 | loss = 0.750, acc = 0.700\n","Epoch 1 | Step 1100 | loss = 0.736, acc = 0.697\n","Epoch 1 | Step 1200 | loss = 0.689, acc = 0.724\n","Epoch 1 | Step 1300 | loss = 0.682, acc = 0.725\n","Epoch 1 | Step 1400 | loss = 0.687, acc = 0.714\n","Epoch 1 | Step 1500 | loss = 0.661, acc = 0.716\n","Epoch 1 | Step 1600 | loss = 0.676, acc = 0.721\n","\n","Evaluating Dev Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c8a5cb3045548ab9bce3c6101ce8452","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3524.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Validation | Epoch 1 | acc = 0.726\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a08110e1deba4ac49b7fef7f50051c9f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1684.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 2 | Step 100 | loss = 0.481, acc = 0.773\n","Epoch 2 | Step 200 | loss = 0.425, acc = 0.794\n","Epoch 2 | Step 300 | loss = 0.461, acc = 0.788\n","Epoch 2 | Step 400 | loss = 0.443, acc = 0.794\n","Epoch 2 | Step 500 | loss = 0.499, acc = 0.786\n","Epoch 2 | Step 600 | loss = 0.459, acc = 0.779\n","Epoch 2 | Step 700 | loss = 0.443, acc = 0.796\n","Epoch 2 | Step 800 | loss = 0.448, acc = 0.801\n","Epoch 2 | Step 900 | loss = 0.432, acc = 0.796\n","Epoch 2 | Step 1000 | loss = 0.463, acc = 0.795\n","Epoch 2 | Step 1100 | loss = 0.414, acc = 0.806\n","Epoch 2 | Step 1200 | loss = 0.393, acc = 0.809\n","Epoch 2 | Step 1300 | loss = 0.410, acc = 0.817\n","Epoch 2 | Step 1400 | loss = 0.429, acc = 0.802\n","Epoch 2 | Step 1500 | loss = 0.401, acc = 0.815\n","Epoch 2 | Step 1600 | loss = 0.392, acc = 0.825\n","\n","Evaluating Dev Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01cc62fd4eb2457389e5d1e565b450ec","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3524.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Validation | Epoch 2 | acc = 0.750\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a0e6551fc3b4f3c84ba6a1c9423ceeb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1684.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 3 | Step 100 | loss = 0.259, acc = 0.867\n","Epoch 3 | Step 200 | loss = 0.278, acc = 0.865\n","Epoch 3 | Step 300 | loss = 0.270, acc = 0.856\n","Epoch 3 | Step 400 | loss = 0.278, acc = 0.857\n","Epoch 3 | Step 500 | loss = 0.257, acc = 0.873\n","Epoch 3 | Step 600 | loss = 0.237, acc = 0.881\n","Epoch 3 | Step 700 | loss = 0.233, acc = 0.874\n","Epoch 3 | Step 800 | loss = 0.259, acc = 0.872\n","Epoch 3 | Step 900 | loss = 0.241, acc = 0.878\n","Epoch 3 | Step 1000 | loss = 0.246, acc = 0.876\n","Epoch 3 | Step 1100 | loss = 0.229, acc = 0.877\n","Epoch 3 | Step 1200 | loss = 0.214, acc = 0.890\n","Epoch 3 | Step 1300 | loss = 0.223, acc = 0.887\n","Epoch 3 | Step 1400 | loss = 0.213, acc = 0.878\n","Epoch 3 | Step 1500 | loss = 0.229, acc = 0.881\n","Epoch 3 | Step 1600 | loss = 0.200, acc = 0.881\n","\n","Evaluating Dev Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfa70781babb4b74b31a0160390a28d9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3524.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Validation | Epoch 3 | acc = 0.780\n","Saving Model ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kMmdLOKBMsdE"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"U5scNKC9xz0C","colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["14306b8a3fab4e2bbfa73b0a4d513a3e","8baaa920770f45edbaa75617586d21ca","89a99d3d26a14402ace004b98695d480","08fc2ad196f845c5bc275aca2265ec84","ec35dd5dde0c496db7e8f62816d2d143","078f6e9d2e0949599be4971da928a7f3","2d5919a9f9974cff9916e1bd4a7f7efb","edc87f34a76a4fe19623cba8c5d4c3b4"]},"executionInfo":{"status":"ok","timestamp":1624870587515,"user_tz":-480,"elapsed":124837,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}},"outputId":"0b2fde11-485e-405b-a30b-78eb2ecce238"},"source":["print(\"Evaluating Test Set ...\")\n","\n","result = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for data in tqdm(test_loader):\n","        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n","                       attention_mask=data[2].squeeze(dim=0).to(device))\n","        result.append(evaluate(data, output))\n","\n","result_file = \"result.csv\"\n","with open(result_file, 'w') as f:\t\n","\t  f.write(\"ID,Answer\\n\")\n","\t  for i, test_question in enumerate(test_questions):\n","        # Replace commas in answers with empty strings (since csv is separated by comma)\n","        # Answers in kaggle are processed in the same way\n","\t\t    f.write(f\"{test_question['id']},{result[i].replace(',','')}\\n\")\n","\n","print(f\"Completed! Result is in {result_file}\")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Evaluating Test Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14306b8a3fab4e2bbfa73b0a4d513a3e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3493.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Completed! Result is in result.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F6OoDCbwzZJ1","executionInfo":{"status":"ok","timestamp":1624870587516,"user_tz":-480,"elapsed":8,"user":{"displayName":"Howard Ding","photoUrl":"","userId":"16609764447948458719"}}},"source":[""],"execution_count":28,"outputs":[]}]}